{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language models\n",
    "\n",
    "Maybe here: https://raw.githubusercontent.com/mkearney/trumptweets/master/data/trumptweets-1515775693.tweets.csv\n",
    "\n",
    "A language model is an algorithm that takes a sequence of words, and outputs the likely next word in the sequence. Most language models output a list of words, each with its probability of occurance. For example, if we had a sentence that started `I would like to eat a hot`, then ideally the algorithm would predict that  the word `dog` had a much higher chance of being the next word than the word `meeting`. \n",
    "\n",
    "Language models are a very powerful building block in natural language processing. They are used for classifying text (e.g. is this review positive or negative?), for answering questions based on text (e.g. \"what is the capital of Finland?\" based on the Wikipedia page on Finland), and language translation (e.g. English to Japanese).\n",
    "\n",
    "## The intuition behind why language models are so broadly useful\n",
    "How can this simple sounding algorithm be that broadly useful? Intuitively, this is because predicting the next word in a sentence requires a lot of information, not just about grammar and syntax, but also about semantics: what things mean in the real-world. For instance, we know that `I would like to eat a hot dog` is semantically reasonable, but `I would like to eat a hot cat` is nonsensical. \n",
    "\n",
    "I trained a simple language model, and asked it to predict the word following `I would like to eat a `. \n",
    "\n",
    "We get:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load all the data \n",
    "In this example, we are going to use a dataset of tweets from [the Onion](https://www.theonion.com), as well as some non-sarcastic news sources. I found this data set on [Kaggle](https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection). \n",
    "\n",
    "Before I started creating this notebook, I downloaded the JSON file to a folder `haii-assignment4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_path = Path('./haii-assignment4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is in a JSON file, so I am using the `read_json` method. If your data is CSV, use the `read_csv` method instead. \n",
    "\n",
    "We use the `lines=True` argument here because the author formatted each line as a separate JSON object. I think at least half of your time as a data scientist/AI researcher is spent dealing with other people's data formats!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = pd.read_json(data_path/'Sarcasm_Headlines_Dataset_v2.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28614</th>\n",
       "      <td>1</td>\n",
       "      <td>jews to celebrate rosh hashasha or something</td>\n",
       "      <td>https://www.theonion.com/jews-to-celebrate-ros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28615</th>\n",
       "      <td>1</td>\n",
       "      <td>internal affairs investigator disappointed con...</td>\n",
       "      <td>https://local.theonion.com/internal-affairs-in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28616</th>\n",
       "      <td>0</td>\n",
       "      <td>the most beautiful acceptance speech this week...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/andrew-ah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28617</th>\n",
       "      <td>1</td>\n",
       "      <td>mars probe destroyed by orbiting spielberg-gat...</td>\n",
       "      <td>https://www.theonion.com/mars-probe-destroyed-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28618</th>\n",
       "      <td>1</td>\n",
       "      <td>dad clarifies this not a food stop</td>\n",
       "      <td>https://www.theonion.com/dad-clarifies-this-no...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28619 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_sarcastic                                           headline  \\\n",
       "0                 1  thirtysomething scientists unveil doomsday clo...   \n",
       "1                 0  dem rep. totally nails why congress is falling...   \n",
       "2                 0  eat your veggies: 9 deliciously different recipes   \n",
       "3                 1  inclement weather prevents liar from getting t...   \n",
       "4                 1  mother comes pretty close to using word 'strea...   \n",
       "...             ...                                                ...   \n",
       "28614             1       jews to celebrate rosh hashasha or something   \n",
       "28615             1  internal affairs investigator disappointed con...   \n",
       "28616             0  the most beautiful acceptance speech this week...   \n",
       "28617             1  mars probe destroyed by orbiting spielberg-gat...   \n",
       "28618             1                 dad clarifies this not a food stop   \n",
       "\n",
       "                                            article_link  \n",
       "0      https://www.theonion.com/thirtysomething-scien...  \n",
       "1      https://www.huffingtonpost.com/entry/donna-edw...  \n",
       "2      https://www.huffingtonpost.com/entry/eat-your-...  \n",
       "3      https://local.theonion.com/inclement-weather-p...  \n",
       "4      https://www.theonion.com/mother-comes-pretty-c...  \n",
       "...                                                  ...  \n",
       "28614  https://www.theonion.com/jews-to-celebrate-ros...  \n",
       "28615  https://local.theonion.com/internal-affairs-in...  \n",
       "28616  https://www.huffingtonpost.com/entry/andrew-ah...  \n",
       "28617  https://www.theonion.com/mars-probe-destroyed-...  \n",
       "28618  https://www.theonion.com/dad-clarifies-this-no...  \n",
       "\n",
       "[28619 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, some of this dataset is drawn from the onion, the rest is drawn from places like the Huffington Post which publish real news, not satire. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1a: Examine the data set (5 points)\n",
    "\n",
    "Before we go off adventuring, let's first see what this dataset looks like. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: How large is this dataset? Is it balanced? (1 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14985\n",
       "1    13634\n",
       "Name: is_sarcastic, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert code here to check size of dataset, and how many are positive (is_sarcastic = 1) and how many negative?\n",
    "# Hint: Your output will look like this.\n",
    "is_sarcastic = headlines['is_sarcastic'] #create dataframe \n",
    "is_sarcastic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The dataset is balanced because the number of `is_sarcastic = 0` and `is_sarcastic = 1` are almost equal in number. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: How long on average is each headline? (4 points)\n",
    "Longer text = more information. We want to see what the length of the headline is in order to see how much information it may have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        61\n",
       "1        79\n",
       "2        49\n",
       "3        52\n",
       "4        61\n",
       "         ..\n",
       "28614    44\n",
       "28615    87\n",
       "28616    71\n",
       "28617    61\n",
       "28618    34\n",
       "Name: headline, Length: 28619, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert code here to find the average length of headline (in words)\n",
    "## Hint: see https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.count.html \n",
    "# the '\\s' regex looks for spaces.\n",
    "headline = headlines['headline']\n",
    "headline.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.30857122890387"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline.str.len().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Each headline has 62 characters on an average. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Build a language model that knows how to write news headlines\n",
    "\n",
    "This is the first step of our project that will be using a machine learning model. \n",
    "\n",
    "We are going to use the [fast.ai](https://fast.ai/) library to create this model. If you need help with understanding this section, look at the fast.ai documentation -- it is fantastic! The steps below are modified from the [online tutorial](https://docs.fast.ai/text.html#Quick-Start:-Training-an-IMDb-sentiment-model-with-ULMFiT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai.text import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: if this import fails for you, make sure you've installed fastai first. Do that by creating a new cell, and typing `!pip install fastai`*\n",
    "\n",
    "*Note to self: I had to use `conda install -c pytorch -c fastai fastai` in the env in which I am running this notebook instead of `!pip install fastai`. Pip install did not install bottleneck package and some others when run in command line. Code reference for the same can be found [here.](https://github.com/fastai/fastai)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = (TextList.from_df(headlines, path=data_path, cols='headline').split_none().label_for_lm().databunch())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So here is what happened above. \n",
    "\n",
    "First, we tell fastai that we want to work on a list of texts (headlines in our case), that are stored in a dataframe (that's the `TextList.from_df` part.) We also pass in our data path, so after we process our data, we can store it at that location. Finally, we tell it where to look for the headline in the dataframe (which column to use, `cols=`). \n",
    "\n",
    "Then there are two other important parts. We'll take it from the end. A `databunch` is a fastai convenience. It keeps all your training, validation and test data together. But what kind of validation data do we need for a language model? Remember that a language model predicts the next word in an input sequence of words. So, we can't just take some of the headlines and set them aside as validation. Instead, we want to use all the sentences and validate whether we can guess the right next word some fraction of the time. So, we first say `split_none` so you use all your data. Then we say `label_for_lm` so it labels the \"next word\" as the label for each sequence of words. It's a clever method -- see the source if you're curious!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.save('data_lm_export.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save this databunch. We'll use this saved copy later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2a: Learn the model\n",
    "\n",
    "Now that we have the data, it's time to train the model.\n",
    "\n",
    "Now, we *could* learn a language model from scratch. But we're instead going to cheat. We're going to use a pretrained language model, and finetune it for our purpose. Specifically, we're going to use a model trained on the `Wikitext-103` corpus. \n",
    "\n",
    "One way to understand it is to think of our pre-trained model is as a model that can predict the next word in a Wikipedia article. We want to train it to write headlines instead. Since headlines still have to sound like English, ie. follow grammar, syntax, be generally plausible etc, being able to predict the next word in Wikipedia is super useful. It allows us to start with a model that already knows some English, and then just train it for writing headlines.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `AWD_LSTM` is the pretrained Wikipedia model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.062365</td>\n",
       "      <td>#na#</td>\n",
       "      <td>04:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once trained, it's time to write some headlines! We give it a starting sequence `Students protest ` and see what it comes up with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Students protest  from stop in raised neighborhood'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"Students protest \", n_words=5, no_unk=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good, huh? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Fed is expected to hold 14 %'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('The Fed is expected to', n_words=3, no_unk=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, it's not perfect! Let's make it a little better. \n",
    "\n",
    "The `unfreeze` below is telling fastai to allow us to change the weights throughout the model. We do this when we want to make the model generate text that's more similar to our headlines (than to Wikipedia). \n",
    "\n",
    "*Note to self: `unfreeze` will unfreeze all layers of your model, so you will be training the early and later layers, although you still may be training the different layer groups at different learning rates. This is called â€˜discriminative learning ratesâ€™ or â€˜discriminative layer trainingâ€™. Referenced from a [fast.ai forum](https://forums.fast.ai/t/can-anyone-explain-me-what-does-freeze-and-unfreeze-do/42025).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.178275</td>\n",
       "      <td>#na#</td>\n",
       "      <td>06:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(cyc_len=1, max_lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New Study finds scientific economics anti -'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('New Study', n_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'16 Problems with an empire xxbos signature'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('16 Problems', n_words=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now let's save our hard work. We'll use this later. (Pssst: why is it called an encoder? Look at the Fastai docs to find out!)\n",
    "\n",
    "*Note to self: The `encoder` is essentially tasked with creating a mathematical representation of the language based on the task for predicting the next word. A `decoder` is responsible for taking that representation and applying it to some problem (e.g., predicting the next word, understanding sentiment, etc.). Referenced from a [fast.ai forum](https://forums.fast.ai/t/what-is-an-encoder-and-what-is-save-load-encoder-actually-doing/8281/3).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('headlines-awd.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we also want to save the whole model, so we can reuse it in our twitter bot. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export('headlines-lm.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2b: See how well the language model works (15 points)\n",
    "\n",
    "Try generating a few more headlines. Then, answer the following questions. Wherever possible, show what code you ran, or what predictions you asked it for. *Suggestion: Try using punctuations, numbers, texts of different lengths etc.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: What is the effect of starting with longer strings? (5 points)\n",
    "\n",
    "We could start our headline generation with just one word, e.g. `learn.predict('White', n_words=9)` or with many: `learn.predict('White House Says Whistleblower Did', n_words=5)`. What is the difference you see in the kinds of headlines generated?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'White house officials agree to issue ethics enforcement semitic payments'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your answer here. Insert more cells if you want to insert code etc.\n",
    "learn.predict('White', n_words=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'White house recipients choose to'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('White', n_words=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"White House Says Whistleblower Did ' die he got it\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('White House Says Whistleblower Did', n_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'White House is located in the theater'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('White House is located in', n_words=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'White House is located in elusive flying carrier , looking famous gubernatorial vermont xxbos population'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('White House is located in', n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'White House is located in Chicago where it runs past 12 location dog not'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('White House is located in', n_words=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: After experimenting a bit, I think that headlines that start with more words are more specific to what we may be looking for. However, the higher the number of words, the more likely it is for the model to give out unidentifiable words in the sentence such as those that start with xxbos etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: What aspects of the task of generating headlines does our language model do well? (5 points)\n",
    "For example, does it get grammar right? Does it know genders of people or objects? etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Donald Trump is the president of the new york times'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your answer here. Insert more cells if you want to insert code etc.\n",
    "learn.predict('Donald Trump is the president', n_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Inclement weather prevents liars from arriving end of year'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('Inclement weather prevents liars from', n_words=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Here is the list of what all the model does well, according to me: \n",
    "* The model uses advanced words such as gubernatorial, semitic etc. (these words might vanish from the above lines in case the notebook is run again.)\n",
    "* The model uses numbers and words together. \n",
    "* The model is able to generate the names of famous celebrities, and uses them with their name and surname."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q: What aspects of the task of generating headlines does our model do poorly? (5 points)\n",
    "What does it frequently get wrong? Why might it make these mistakes?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'twinkle twinkle little bit for'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your answer here\n",
    "learn.predict('twinkle twinkle little', n_words=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Here is the list of what all the model does poorly, according to me: \n",
    "* Grammar is fequently wrong, I think that this is because even after learning from Wikipedia, the model still needs to be taught the rules of sentence formation and grammar usage.\n",
    "* When the number of words specified are more than 3 or 4, the model starts adding xxbos at unpredicted places. \n",
    "* Sometimes the model gives out lesser words than what the user has asked for. \n",
    "* The model does not know context or associations such as, Michael Jordan is a basketball player, or that Donald Trump is the president of USA. This is because the sentence generation is random.\n",
    "* The model is unable to complete poems known by everyone, such as 'twinkle twinkle little star'. This is perhaps because the Wikipedia pages might not contain this information.\n",
    "* The model is unable to start a new sentence. Rather, it adds commas. This is because even punctuation is something that needs to be taught to the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Learn a classifier to see which headlines are satire\n",
    "\n",
    "Remember, our dataset has some stories that are satire (from the Onion) and others that are real. Now, we're going to train a classifier to distinguish one from the other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = (TextList.from_df(df=headlines, path=data_path, vocab= data_lm.train_ds.vocab, cols='headline').split_by_rand_pct(valid_pct=0.2).label_from_df(cols='is_sarcastic').databunch())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using a similar databunch method as we did for our language model above. Here, we are using `split_by_rand_pct` so we keep some fraction of our dataset as a validation set. There is one other trick: `vocab= data_lm.train_ds.vocab` ensures that our classifier only uses words that we have in our language model -- so it never deals with words it hasn't encountered before. (Consider: why is this important?)\n",
    "\n",
    "*Note to self: `data_lm.train_ds.vocab` this could be important so that the context and intent pertain to the dataset. But this could also be a limiting factor for the type of responses that are given out.*\n",
    "\n",
    "See if you can work out what the other arguments are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos hot wheels ranked number one toy for rolling down ramp , knocking over xxunk that send xxunk down a funnel , dropping onto teeter - xxunk that yanks on string , causing xxunk system to raise wooden block , xxunk series of twine xxunk that unwind spring , launching tennis ball across room , xxunk tire down slope until it hits power switch , xxunk table fan that blows</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos ' how do we treat the little people , joan ? ' i asked . and she said , ' why , we treat them better . we only s -- t on people at our level or higher . '</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos jared kushner claims that russian interference less damaging to u.s . democracy than saudi arabia , nepotism , israel , cambridge analytica , uae , illicit donations , erik prince , bill barr , and financial xxunk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos ' men are not xxunk , ' says woman who has no idea what it like to take two whole xxunk to get to your clothing section at zara</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos annoying guy in movie theater constantly screaming ' get out of there , you idiot ' at bradley cooper 's character in ' a star is born '</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above: what our data looks like after we apply the vocabulary restriction. `xxunk` is an unknown word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: we're creating a classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify = text_classifier_learner(data=data_clas, arch=AWD_LSTM, drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that language model we saved earlier? It's time load it back!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (22896 items)\n",
       "x: TextList\n",
       "xxbos xxunk scientists unveil doomsday clock of hair loss,xxbos dem rep . totally nails why congress is falling short on gender , racial equality,xxbos mother comes pretty close to using word ' streaming ' correctly,xxbos my white inheritance,xxbos 5 ways to file your taxes with less stress\n",
       "y: CategoryList\n",
       "1,0,1,0,0\n",
       "Path: haii-assignment4;\n",
       "\n",
       "Valid: LabelList (5723 items)\n",
       "x: TextList\n",
       "xxbos someone xxunk the ' elf ' trailer as a thriller , and it 's terrifying,xxbos gun lobbyist warns gun owners could resort to ' bullet box ' if they do n't like election results,xxbos man stays up most of night rocking cat back to sleep,xxbos ariana grande xxunk saves tidal with musical xxunk on ' snl ',xxbos fired u.s . attorney xxunk xxunk said to have been investigating hhs secretary tom price\n",
       "y: CategoryList\n",
       "0,0,1,0,0\n",
       "Path: haii-assignment4;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(11152, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(11152, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x1a2b646050>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('haii-assignment4'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: ...\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(11152, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(11152, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.load_encoder('headlines-awd.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening here? \n",
    "\n",
    "Here's the trick: a language model predicts the next word in a sequence using all the information it has so far (all the previous words). When we train a classifier, we ask it to predict the label (satire or not) instead of the next word. \n",
    "\n",
    "The intuition here is that if you can tell what the next word in a sentence is, you can tell if it is satirical. (Similarly, if you can can tell what the next word in an email is, you can tell if it is spam, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.445014</td>\n",
       "      <td>0.373388</td>\n",
       "      <td>0.835226</td>\n",
       "      <td>02:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classify.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above: this is similar to `unfreeze()` that we used before. Except, you only allow a few layers of your model to change. Then we can train again, similar to using `unfreeze()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.392299</td>\n",
       "      <td>0.329438</td>\n",
       "      <td>0.857417</td>\n",
       "      <td>02:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classify.fit_one_cycle(1, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! An accuracy of 85%! That sounds great, and for not that much work. \n",
    "\n",
    "Now, let's try it on some headlines, to see how well it does. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: try out the classifier (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.8974, 0.1026]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(\"Despair for Many and Silver Linings for Some in California Wildfires\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here in the output, the first part of this tuple is the chosen category (`0`, i.e. not satire), and the last part is an array of probabilities. The classifier suggests that the headline (which I got from the [New York Times](https://www.nytimes.com/2019/10/29/us/california-fires-homes.html?action=click&module=Top%20Stories&pgtype=Homepage)) is not satire, with about an 86% confidence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4a: Try out this classifier (10 points)\n",
    "\n",
    "Below, try the classifier with some headlines, real or made up (including made up by the language model above). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Two headlines that the classifier correctly classifies (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.6481, 0.3519]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(\"Joker' smashes October box office record with $93.5M debut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.0679, 0.9321]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(\"Woman wakes up to find a cat staring in her face\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Two headlines that the classifier classifies incorrectly (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.9494, 0.0506]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(\"You may be at risk of throat cancer if you have a throat or mouth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.8899, 0.1101]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(\"Man takes a Harley Davidson bike for a test ride and steals it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to find two headlines that the classifier is really confident about, but classifies incorrectly. We want the confidence of the prediction to be at least 85%.\n",
    "\n",
    "One headline is anything you want to write. Another must be a real headline (not satire) that you could trick the classifier into misclassifying changing only one word. For instance, taking `\"Despair for Many and Silver Linings for Some in California Wildfires\"`, a real NYTimes headline, you can change it to `\"Despair for Many and Silver Linings for Some in Oregon Wildfires\"` (note that this particular change does not cause the classifier to misclassify)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.8899, 0.1101]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Insert one headline that the classifier classifies incorrectly, with false high confidence. (4 points)\n",
    "classify.predict(\"Man takes a Harley Davidson bike for a test ride and steals it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.6315, 0.3685]))"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Insert one headline that the classifier classifies incorrectly, with false high confidence. (4 points)\n",
    "classify.predict(\"Mississippi judge accused of selling fake party plans to senior citizens\")\n",
    "# Also, insert link to the original headline/article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link to original headline: https://www.wmcactionnews5.com/2019/05/21/mississippi-coroner-accused-selling-fake-funeral-plans-senior-citizens/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.4767, 0.5233]))"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(\"Mississippi coroner accused of selling fake funeral plans to senior citizens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4b: What kinds of headlines are misclassified? (10 points)\n",
    "\n",
    "Write your hypothesis below on what kinds of headlines are misclassified. If it helps you, use the [TextClassificationInterpretation](https://docs.fast.ai/text.learner.html#TextClassificationInterpretation) utility. Show your work, especially if you use this utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show work here\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/distiller/project/conda/conda-bld/pytorch_1570710797334/work/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/Users/distiller/project/conda/conda-bld/pytorch_1570710797334/work/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/Users/distiller/project/conda/conda-bld/pytorch_1570710797334/work/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/Users/distiller/project/conda/conda-bld/pytorch_1570710797334/work/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace;\"><span title=\"0.241\" style=\"background-color: rgba(219, 219, 235, 0.5);\">xxbos</span> <span title=\"0.187\" style=\"background-color: rgba(229, 227, 240, 0.5);\">xxmaj</span> <span title=\"0.642\" style=\"background-color: rgba(124, 118, 182, 0.5);\">mississippi</span> <span title=\"1.000\" style=\"background-color: rgba(63, 0, 125, 0.5);\">coroner</span> <span title=\"0.439\" style=\"background-color: rgba(172, 171, 209, 0.5);\">accused</span> <span title=\"0.131\" style=\"background-color: rgba(238, 236, 244, 0.5);\">of</span> <span title=\"0.474\" style=\"background-color: rgba(164, 161, 204, 0.5);\">selling</span> <span title=\"0.515\" style=\"background-color: rgba(154, 150, 198, 0.5);\">fake</span> <span title=\"0.197\" style=\"background-color: rgba(227, 226, 239, 0.5);\">party</span> <span title=\"0.212\" style=\"background-color: rgba(224, 223, 238, 0.5);\">plans</span> <span title=\"0.121\" style=\"background-color: rgba(239, 237, 245, 0.5);\">to</span> <span title=\"0.539\" style=\"background-color: rgba(148, 144, 195, 0.5);\">senior</span> <span title=\"0.237\" style=\"background-color: rgba(220, 220, 236, 0.5);\">citizens</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "txt_ci = TextClassificationInterpretation.from_learner(classify)\n",
    "test_text = \"Mississippi coroner accused of selling fake party plans to senior citizens\"\n",
    "txt_ci.show_intrinsic_attention(test_text,cmap=cm.Purples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/distiller/project/conda/conda-bld/pytorch_1570710797334/work/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/Users/distiller/project/conda/conda-bld/pytorch_1570710797334/work/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/Users/distiller/project/conda/conda-bld/pytorch_1570710797334/work/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/Users/distiller/project/conda/conda-bld/pytorch_1570710797334/work/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2414, 0.1866, 0.6415, 1.0000, 0.4387, 0.1313, 0.4741, 0.5150, 0.1970,\n",
       "        0.2122, 0.1205, 0.5394, 0.2369])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_ci.intrinsic_attention(test_text)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/distiller/project/conda/conda-bld/pytorch_1570710797334/work/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/Users/distiller/project/conda/conda-bld/pytorch_1570710797334/work/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/Users/distiller/project/conda/conda-bld/pytorch_1570710797334/work/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n",
      "/Users/distiller/project/conda/conda-bld/pytorch_1570710797334/work/aten/src/ATen/native/LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace;\"><span title=\"0.172\" style=\"background-color: rgba(231, 229, 241, 0.5);\">xxbos</span> <span title=\"0.157\" style=\"background-color: rgba(233, 232, 242, 0.5);\">xxmaj</span> <span title=\"0.330\" style=\"background-color: rgba(198, 199, 225, 0.5);\">you</span> <span title=\"0.246\" style=\"background-color: rgba(218, 218, 235, 0.5);\">may</span> <span title=\"0.128\" style=\"background-color: rgba(238, 236, 244, 0.5);\">be</span> <span title=\"0.128\" style=\"background-color: rgba(238, 236, 244, 0.5);\">at</span> <span title=\"0.273\" style=\"background-color: rgba(213, 213, 232, 0.5);\">risk</span> <span title=\"0.085\" style=\"background-color: rgba(243, 241, 247, 0.5);\">of</span> <span title=\"0.411\" style=\"background-color: rgba(179, 178, 214, 0.5);\">throat</span> <span title=\"0.183\" style=\"background-color: rgba(229, 228, 240, 0.5);\">cancer</span> <span title=\"0.160\" style=\"background-color: rgba(232, 231, 242, 0.5);\">if</span> <span title=\"0.180\" style=\"background-color: rgba(229, 228, 240, 0.5);\">you</span> <span title=\"0.206\" style=\"background-color: rgba(225, 225, 238, 0.5);\">have</span> <span title=\"0.218\" style=\"background-color: rgba(223, 223, 237, 0.5);\">a</span> <span title=\"1.000\" style=\"background-color: rgba(63, 0, 125, 0.5);\">throat</span> <span title=\"0.252\" style=\"background-color: rgba(217, 217, 234, 0.5);\">or</span> <span title=\"0.338\" style=\"background-color: rgba(197, 197, 224, 0.5);\">mouth</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "txt_ci = TextClassificationInterpretation.from_learner(classify)\n",
    "test_text = \"You may be at risk of throat cancer if you have a throat or mouth\"\n",
    "txt_ci.show_intrinsic_attention(test_text,cmap=cm.Purples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Add your interpretation here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Save your classifier\n",
    "Now that we've trained the classifier, you're ready for Part 2. You'll use this saved file in your bot later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify.export(file='satire_awd.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, you'll use it like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "serve_classifier = load_learner(path=data_path, file='satire_awd.pkl')\n",
    "serve_lm = load_learner(path=data_path, file='headlines-lm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.9793, 0.0207]))"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serve_classifier.predict('How the New Syria Took Shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rising Seas : the 6 gates going which have'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serve_lm.predict('Rising Seas', n_words=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: add the bot code. \n",
    "\n",
    "See the assignment document for what the bot code should look like. You can add it just below here, but you are also welcome to create a new notebook where you put that code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Process of building the bot:*\n",
    "* tweepy installed in new env for this notebook using `conda install -c conda-forge tweepy` in command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary methods from tweepy library\n",
    "import tweepy\n",
    "import credentials\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harshika Jain\n"
     ]
    }
   ],
   "source": [
    "user = api.me()\n",
    "print (user.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status(_api=<tweepy.api.API object at 0x1a2f29e210>, _json={'created_at': 'Mon Nov 04 14:27:07 +0000 2019', 'id': 1191361234035236865, 'id_str': '1191361234035236865', 'text': 'Team Presentation Photos from @IBM #BlueHack are now up on our FB page! Go check them out &amp; tag your team members!â€¦ https://t.co/0ZkSVws57k', 'truncated': True, 'entities': {'hashtags': [{'text': 'BlueHack', 'indices': [35, 44]}], 'symbols': [], 'user_mentions': [{'screen_name': 'IBM', 'name': 'IBM', 'id': 18994444, 'id_str': '18994444', 'indices': [30, 34]}], 'urls': [{'url': 'https://t.co/0ZkSVws57k', 'expanded_url': 'https://twitter.com/i/web/status/1191361234035236865', 'display_url': 'twitter.com/i/web/status/1â€¦', 'indices': [120, 143]}]}, 'metadata': {'iso_language_code': 'en', 'result_type': 'recent'}, 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'user': {'id': 1071074428249874432, 'id_str': '1071074428249874432', 'name': 'Big Idea Center', 'screen_name': 'pittbigidea', 'location': 'Pittsburgh, PA', 'description': '', 'url': 'https://t.co/GekHobYArE', 'entities': {'url': {'urls': [{'url': 'https://t.co/GekHobYArE', 'expanded_url': 'http://innovation.pitt.edu/bigideacenter', 'display_url': 'innovation.pitt.edu/bigideacenter', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 129, 'friends_count': 130, 'listed_count': 0, 'created_at': 'Fri Dec 07 16:10:18 +0000 2018', 'favourites_count': 53, 'utc_offset': None, 'time_zone': None, 'geo_enabled': True, 'verified': False, 'statuses_count': 168, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1071074550262235137/AnSGP4c-_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1071074550262235137/AnSGP4c-_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1071074428249874432/1544714592', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': True, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none'}, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'lang': 'en'}, created_at=datetime.datetime(2019, 11, 4, 14, 27, 7), id=1191361234035236865, id_str='1191361234035236865', text='Team Presentation Photos from @IBM #BlueHack are now up on our FB page! Go check them out &amp; tag your team members!â€¦ https://t.co/0ZkSVws57k', truncated=True, entities={'hashtags': [{'text': 'BlueHack', 'indices': [35, 44]}], 'symbols': [], 'user_mentions': [{'screen_name': 'IBM', 'name': 'IBM', 'id': 18994444, 'id_str': '18994444', 'indices': [30, 34]}], 'urls': [{'url': 'https://t.co/0ZkSVws57k', 'expanded_url': 'https://twitter.com/i/web/status/1191361234035236865', 'display_url': 'twitter.com/i/web/status/1â€¦', 'indices': [120, 143]}]}, metadata={'iso_language_code': 'en', 'result_type': 'recent'}, source='Twitter for iPhone', source_url='http://twitter.com/download/iphone', in_reply_to_status_id=None, in_reply_to_status_id_str=None, in_reply_to_user_id=None, in_reply_to_user_id_str=None, in_reply_to_screen_name=None, author=User(_api=<tweepy.api.API object at 0x1a2f29e210>, _json={'id': 1071074428249874432, 'id_str': '1071074428249874432', 'name': 'Big Idea Center', 'screen_name': 'pittbigidea', 'location': 'Pittsburgh, PA', 'description': '', 'url': 'https://t.co/GekHobYArE', 'entities': {'url': {'urls': [{'url': 'https://t.co/GekHobYArE', 'expanded_url': 'http://innovation.pitt.edu/bigideacenter', 'display_url': 'innovation.pitt.edu/bigideacenter', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 129, 'friends_count': 130, 'listed_count': 0, 'created_at': 'Fri Dec 07 16:10:18 +0000 2018', 'favourites_count': 53, 'utc_offset': None, 'time_zone': None, 'geo_enabled': True, 'verified': False, 'statuses_count': 168, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1071074550262235137/AnSGP4c-_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1071074550262235137/AnSGP4c-_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1071074428249874432/1544714592', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': True, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none'}, id=1071074428249874432, id_str='1071074428249874432', name='Big Idea Center', screen_name='pittbigidea', location='Pittsburgh, PA', description='', url='https://t.co/GekHobYArE', entities={'url': {'urls': [{'url': 'https://t.co/GekHobYArE', 'expanded_url': 'http://innovation.pitt.edu/bigideacenter', 'display_url': 'innovation.pitt.edu/bigideacenter', 'indices': [0, 23]}]}, 'description': {'urls': []}}, protected=False, followers_count=129, friends_count=130, listed_count=0, created_at=datetime.datetime(2018, 12, 7, 16, 10, 18), favourites_count=53, utc_offset=None, time_zone=None, geo_enabled=True, verified=False, statuses_count=168, lang=None, contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='F5F8FA', profile_background_image_url=None, profile_background_image_url_https=None, profile_background_tile=False, profile_image_url='http://pbs.twimg.com/profile_images/1071074550262235137/AnSGP4c-_normal.jpg', profile_image_url_https='https://pbs.twimg.com/profile_images/1071074550262235137/AnSGP4c-_normal.jpg', profile_banner_url='https://pbs.twimg.com/profile_banners/1071074428249874432/1544714592', profile_link_color='1DA1F2', profile_sidebar_border_color='C0DEED', profile_sidebar_fill_color='DDEEF6', profile_text_color='333333', profile_use_background_image=True, has_extended_profile=False, default_profile=True, default_profile_image=False, following=False, follow_request_sent=False, notifications=False, translator_type='none'), user=User(_api=<tweepy.api.API object at 0x1a2f29e210>, _json={'id': 1071074428249874432, 'id_str': '1071074428249874432', 'name': 'Big Idea Center', 'screen_name': 'pittbigidea', 'location': 'Pittsburgh, PA', 'description': '', 'url': 'https://t.co/GekHobYArE', 'entities': {'url': {'urls': [{'url': 'https://t.co/GekHobYArE', 'expanded_url': 'http://innovation.pitt.edu/bigideacenter', 'display_url': 'innovation.pitt.edu/bigideacenter', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 129, 'friends_count': 130, 'listed_count': 0, 'created_at': 'Fri Dec 07 16:10:18 +0000 2018', 'favourites_count': 53, 'utc_offset': None, 'time_zone': None, 'geo_enabled': True, 'verified': False, 'statuses_count': 168, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1071074550262235137/AnSGP4c-_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1071074550262235137/AnSGP4c-_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1071074428249874432/1544714592', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': True, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none'}, id=1071074428249874432, id_str='1071074428249874432', name='Big Idea Center', screen_name='pittbigidea', location='Pittsburgh, PA', description='', url='https://t.co/GekHobYArE', entities={'url': {'urls': [{'url': 'https://t.co/GekHobYArE', 'expanded_url': 'http://innovation.pitt.edu/bigideacenter', 'display_url': 'innovation.pitt.edu/bigideacenter', 'indices': [0, 23]}]}, 'description': {'urls': []}}, protected=False, followers_count=129, friends_count=130, listed_count=0, created_at=datetime.datetime(2018, 12, 7, 16, 10, 18), favourites_count=53, utc_offset=None, time_zone=None, geo_enabled=True, verified=False, statuses_count=168, lang=None, contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='F5F8FA', profile_background_image_url=None, profile_background_image_url_https=None, profile_background_tile=False, profile_image_url='http://pbs.twimg.com/profile_images/1071074550262235137/AnSGP4c-_normal.jpg', profile_image_url_https='https://pbs.twimg.com/profile_images/1071074550262235137/AnSGP4c-_normal.jpg', profile_banner_url='https://pbs.twimg.com/profile_banners/1071074428249874432/1544714592', profile_link_color='1DA1F2', profile_sidebar_border_color='C0DEED', profile_sidebar_fill_color='DDEEF6', profile_text_color='333333', profile_use_background_image=True, has_extended_profile=False, default_profile=True, default_profile_image=False, following=False, follow_request_sent=False, notifications=False, translator_type='none'), geo=None, coordinates=None, place=None, contributors=None, is_quote_status=False, retweet_count=0, favorite_count=0, favorited=False, retweeted=False, possibly_sensitive=False, lang='en')\n"
     ]
    }
   ],
   "source": [
    "# Define the search\n",
    "query = '@CMUInnovation'\n",
    "max_tweets = 100\n",
    "\n",
    "# Do the search\n",
    "searched_tweets = []\n",
    "last_id = -1\n",
    "while len(searched_tweets) < max_tweets:\n",
    "    count = max_tweets - len(searched_tweets)\n",
    "    try:\n",
    "        new_tweets = api.search(q=query, count=count, max_id=str(last_id - 1))\n",
    "        if not new_tweets:\n",
    "            break\n",
    "        searched_tweets.extend(new_tweets)\n",
    "        last_id = new_tweets[-1].id\n",
    "    except tweepy.TweepError as e:\n",
    "        # depending on TweepError.code, one may want to retry or wait to keep things simple, \n",
    "        #we will give up on an error                                                                                                                          \n",
    "        break\n",
    "\n",
    "# Iterate over the search\n",
    "for status in searched_tweets:\n",
    "  # do something with all these tweets                                                                                                                                                \n",
    "  print\t(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(_api=<tweepy.api.API object at 0x1a2f29e210>, _json={'created_at': 'Mon Nov 04 20:33:16 +0000 2019', 'id': 1191453378766868480, 'id_str': '1191453378766868480', 'text': 'Iâ€™m on a plane!', 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': []}, 'source': '<a href=\"https://www.github.com/harshikerfuffle\" rel=\"nofollow\">harapug</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'user': {'id': 704772464769765376, 'id_str': '704772464769765376', 'name': 'Harshika Jain', 'screen_name': 'harshikerfuffle', 'location': 'Pittsburgh, PA', 'description': 'User Experience Designer | NIDian | Tartan', 'url': 'https://t.co/ZZ9imZvwFE', 'entities': {'url': {'urls': [{'url': 'https://t.co/ZZ9imZvwFE', 'expanded_url': 'http://cryptdecrypt.blogspot.in', 'display_url': 'cryptdecrypt.blogspot.in', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 99, 'friends_count': 393, 'listed_count': 2, 'created_at': 'Tue Mar 01 20:57:04 +0000 2016', 'favourites_count': 687, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 420, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': '000000', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme9/bg.gif', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme9/bg.gif', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1141340441939513346/zLPwA6rs_normal.png', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1141340441939513346/zLPwA6rs_normal.png', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/704772464769765376/1457153670', 'profile_link_color': '19CF86', 'profile_sidebar_border_color': '000000', 'profile_sidebar_fill_color': '000000', 'profile_text_color': '000000', 'profile_use_background_image': False, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'can_media_tag': True, 'followed_by': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none'}, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'en'}, created_at=datetime.datetime(2019, 11, 4, 20, 33, 16), id=1191453378766868480, id_str='1191453378766868480', text='Iâ€™m on a plane!', truncated=False, entities={'hashtags': [], 'symbols': [], 'user_mentions': [], 'urls': []}, source='harapug', source_url='https://www.github.com/harshikerfuffle', in_reply_to_status_id=None, in_reply_to_status_id_str=None, in_reply_to_user_id=None, in_reply_to_user_id_str=None, in_reply_to_screen_name=None, author=User(_api=<tweepy.api.API object at 0x1a2f29e210>, _json={'id': 704772464769765376, 'id_str': '704772464769765376', 'name': 'Harshika Jain', 'screen_name': 'harshikerfuffle', 'location': 'Pittsburgh, PA', 'description': 'User Experience Designer | NIDian | Tartan', 'url': 'https://t.co/ZZ9imZvwFE', 'entities': {'url': {'urls': [{'url': 'https://t.co/ZZ9imZvwFE', 'expanded_url': 'http://cryptdecrypt.blogspot.in', 'display_url': 'cryptdecrypt.blogspot.in', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 99, 'friends_count': 393, 'listed_count': 2, 'created_at': 'Tue Mar 01 20:57:04 +0000 2016', 'favourites_count': 687, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 420, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': '000000', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme9/bg.gif', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme9/bg.gif', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1141340441939513346/zLPwA6rs_normal.png', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1141340441939513346/zLPwA6rs_normal.png', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/704772464769765376/1457153670', 'profile_link_color': '19CF86', 'profile_sidebar_border_color': '000000', 'profile_sidebar_fill_color': '000000', 'profile_text_color': '000000', 'profile_use_background_image': False, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'can_media_tag': True, 'followed_by': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none'}, id=704772464769765376, id_str='704772464769765376', name='Harshika Jain', screen_name='harshikerfuffle', location='Pittsburgh, PA', description='User Experience Designer | NIDian | Tartan', url='https://t.co/ZZ9imZvwFE', entities={'url': {'urls': [{'url': 'https://t.co/ZZ9imZvwFE', 'expanded_url': 'http://cryptdecrypt.blogspot.in', 'display_url': 'cryptdecrypt.blogspot.in', 'indices': [0, 23]}]}, 'description': {'urls': []}}, protected=False, followers_count=99, friends_count=393, listed_count=2, created_at=datetime.datetime(2016, 3, 1, 20, 57, 4), favourites_count=687, utc_offset=None, time_zone=None, geo_enabled=False, verified=False, statuses_count=420, lang=None, contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='000000', profile_background_image_url='http://abs.twimg.com/images/themes/theme9/bg.gif', profile_background_image_url_https='https://abs.twimg.com/images/themes/theme9/bg.gif', profile_background_tile=False, profile_image_url='http://pbs.twimg.com/profile_images/1141340441939513346/zLPwA6rs_normal.png', profile_image_url_https='https://pbs.twimg.com/profile_images/1141340441939513346/zLPwA6rs_normal.png', profile_banner_url='https://pbs.twimg.com/profile_banners/704772464769765376/1457153670', profile_link_color='19CF86', profile_sidebar_border_color='000000', profile_sidebar_fill_color='000000', profile_text_color='000000', profile_use_background_image=False, has_extended_profile=False, default_profile=False, default_profile_image=False, can_media_tag=True, followed_by=False, following=False, follow_request_sent=False, notifications=False, translator_type='none'), user=User(_api=<tweepy.api.API object at 0x1a2f29e210>, _json={'id': 704772464769765376, 'id_str': '704772464769765376', 'name': 'Harshika Jain', 'screen_name': 'harshikerfuffle', 'location': 'Pittsburgh, PA', 'description': 'User Experience Designer | NIDian | Tartan', 'url': 'https://t.co/ZZ9imZvwFE', 'entities': {'url': {'urls': [{'url': 'https://t.co/ZZ9imZvwFE', 'expanded_url': 'http://cryptdecrypt.blogspot.in', 'display_url': 'cryptdecrypt.blogspot.in', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 99, 'friends_count': 393, 'listed_count': 2, 'created_at': 'Tue Mar 01 20:57:04 +0000 2016', 'favourites_count': 687, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 420, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': '000000', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme9/bg.gif', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme9/bg.gif', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1141340441939513346/zLPwA6rs_normal.png', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1141340441939513346/zLPwA6rs_normal.png', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/704772464769765376/1457153670', 'profile_link_color': '19CF86', 'profile_sidebar_border_color': '000000', 'profile_sidebar_fill_color': '000000', 'profile_text_color': '000000', 'profile_use_background_image': False, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'can_media_tag': True, 'followed_by': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none'}, id=704772464769765376, id_str='704772464769765376', name='Harshika Jain', screen_name='harshikerfuffle', location='Pittsburgh, PA', description='User Experience Designer | NIDian | Tartan', url='https://t.co/ZZ9imZvwFE', entities={'url': {'urls': [{'url': 'https://t.co/ZZ9imZvwFE', 'expanded_url': 'http://cryptdecrypt.blogspot.in', 'display_url': 'cryptdecrypt.blogspot.in', 'indices': [0, 23]}]}, 'description': {'urls': []}}, protected=False, followers_count=99, friends_count=393, listed_count=2, created_at=datetime.datetime(2016, 3, 1, 20, 57, 4), favourites_count=687, utc_offset=None, time_zone=None, geo_enabled=False, verified=False, statuses_count=420, lang=None, contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='000000', profile_background_image_url='http://abs.twimg.com/images/themes/theme9/bg.gif', profile_background_image_url_https='https://abs.twimg.com/images/themes/theme9/bg.gif', profile_background_tile=False, profile_image_url='http://pbs.twimg.com/profile_images/1141340441939513346/zLPwA6rs_normal.png', profile_image_url_https='https://pbs.twimg.com/profile_images/1141340441939513346/zLPwA6rs_normal.png', profile_banner_url='https://pbs.twimg.com/profile_banners/704772464769765376/1457153670', profile_link_color='19CF86', profile_sidebar_border_color='000000', profile_sidebar_fill_color='000000', profile_text_color='000000', profile_use_background_image=False, has_extended_profile=False, default_profile=False, default_profile_image=False, can_media_tag=True, followed_by=False, following=False, follow_request_sent=False, notifications=False, translator_type='none'), geo=None, coordinates=None, place=None, contributors=None, is_quote_status=False, retweet_count=0, favorite_count=0, favorited=False, retweeted=False, lang='en')"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.update_status('Iâ€™m on a plane!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(_api=<tweepy.api.API object at 0x1a2f29e210>, _json={'created_at': 'Mon Nov 04 20:33:27 +0000 2019', 'id': 1191453424820326402, 'id_str': '1191453424820326402', 'text': 'this is a reply! @@CMUInnovation', 'truncated': False, 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'CMUInnovation', 'name': 'CMU Innovation', 'id': 2337236814, 'id_str': '2337236814', 'indices': [18, 32]}], 'urls': []}, 'source': '<a href=\"https://www.github.com/harshikerfuffle\" rel=\"nofollow\">harapug</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'user': {'id': 704772464769765376, 'id_str': '704772464769765376', 'name': 'Harshika Jain', 'screen_name': 'harshikerfuffle', 'location': 'Pittsburgh, PA', 'description': 'User Experience Designer | NIDian | Tartan', 'url': 'https://t.co/ZZ9imZvwFE', 'entities': {'url': {'urls': [{'url': 'https://t.co/ZZ9imZvwFE', 'expanded_url': 'http://cryptdecrypt.blogspot.in', 'display_url': 'cryptdecrypt.blogspot.in', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 99, 'friends_count': 393, 'listed_count': 2, 'created_at': 'Tue Mar 01 20:57:04 +0000 2016', 'favourites_count': 687, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 421, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': '000000', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme9/bg.gif', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme9/bg.gif', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1141340441939513346/zLPwA6rs_normal.png', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1141340441939513346/zLPwA6rs_normal.png', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/704772464769765376/1457153670', 'profile_link_color': '19CF86', 'profile_sidebar_border_color': '000000', 'profile_sidebar_fill_color': '000000', 'profile_text_color': '000000', 'profile_use_background_image': False, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'can_media_tag': True, 'followed_by': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none'}, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'en'}, created_at=datetime.datetime(2019, 11, 4, 20, 33, 27), id=1191453424820326402, id_str='1191453424820326402', text='this is a reply! @@CMUInnovation', truncated=False, entities={'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'CMUInnovation', 'name': 'CMU Innovation', 'id': 2337236814, 'id_str': '2337236814', 'indices': [18, 32]}], 'urls': []}, source='harapug', source_url='https://www.github.com/harshikerfuffle', in_reply_to_status_id=None, in_reply_to_status_id_str=None, in_reply_to_user_id=None, in_reply_to_user_id_str=None, in_reply_to_screen_name=None, author=User(_api=<tweepy.api.API object at 0x1a2f29e210>, _json={'id': 704772464769765376, 'id_str': '704772464769765376', 'name': 'Harshika Jain', 'screen_name': 'harshikerfuffle', 'location': 'Pittsburgh, PA', 'description': 'User Experience Designer | NIDian | Tartan', 'url': 'https://t.co/ZZ9imZvwFE', 'entities': {'url': {'urls': [{'url': 'https://t.co/ZZ9imZvwFE', 'expanded_url': 'http://cryptdecrypt.blogspot.in', 'display_url': 'cryptdecrypt.blogspot.in', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 99, 'friends_count': 393, 'listed_count': 2, 'created_at': 'Tue Mar 01 20:57:04 +0000 2016', 'favourites_count': 687, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 421, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': '000000', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme9/bg.gif', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme9/bg.gif', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1141340441939513346/zLPwA6rs_normal.png', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1141340441939513346/zLPwA6rs_normal.png', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/704772464769765376/1457153670', 'profile_link_color': '19CF86', 'profile_sidebar_border_color': '000000', 'profile_sidebar_fill_color': '000000', 'profile_text_color': '000000', 'profile_use_background_image': False, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'can_media_tag': True, 'followed_by': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none'}, id=704772464769765376, id_str='704772464769765376', name='Harshika Jain', screen_name='harshikerfuffle', location='Pittsburgh, PA', description='User Experience Designer | NIDian | Tartan', url='https://t.co/ZZ9imZvwFE', entities={'url': {'urls': [{'url': 'https://t.co/ZZ9imZvwFE', 'expanded_url': 'http://cryptdecrypt.blogspot.in', 'display_url': 'cryptdecrypt.blogspot.in', 'indices': [0, 23]}]}, 'description': {'urls': []}}, protected=False, followers_count=99, friends_count=393, listed_count=2, created_at=datetime.datetime(2016, 3, 1, 20, 57, 4), favourites_count=687, utc_offset=None, time_zone=None, geo_enabled=False, verified=False, statuses_count=421, lang=None, contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='000000', profile_background_image_url='http://abs.twimg.com/images/themes/theme9/bg.gif', profile_background_image_url_https='https://abs.twimg.com/images/themes/theme9/bg.gif', profile_background_tile=False, profile_image_url='http://pbs.twimg.com/profile_images/1141340441939513346/zLPwA6rs_normal.png', profile_image_url_https='https://pbs.twimg.com/profile_images/1141340441939513346/zLPwA6rs_normal.png', profile_banner_url='https://pbs.twimg.com/profile_banners/704772464769765376/1457153670', profile_link_color='19CF86', profile_sidebar_border_color='000000', profile_sidebar_fill_color='000000', profile_text_color='000000', profile_use_background_image=False, has_extended_profile=False, default_profile=False, default_profile_image=False, can_media_tag=True, followed_by=False, following=False, follow_request_sent=False, notifications=False, translator_type='none'), user=User(_api=<tweepy.api.API object at 0x1a2f29e210>, _json={'id': 704772464769765376, 'id_str': '704772464769765376', 'name': 'Harshika Jain', 'screen_name': 'harshikerfuffle', 'location': 'Pittsburgh, PA', 'description': 'User Experience Designer | NIDian | Tartan', 'url': 'https://t.co/ZZ9imZvwFE', 'entities': {'url': {'urls': [{'url': 'https://t.co/ZZ9imZvwFE', 'expanded_url': 'http://cryptdecrypt.blogspot.in', 'display_url': 'cryptdecrypt.blogspot.in', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 99, 'friends_count': 393, 'listed_count': 2, 'created_at': 'Tue Mar 01 20:57:04 +0000 2016', 'favourites_count': 687, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 421, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': '000000', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme9/bg.gif', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme9/bg.gif', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1141340441939513346/zLPwA6rs_normal.png', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1141340441939513346/zLPwA6rs_normal.png', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/704772464769765376/1457153670', 'profile_link_color': '19CF86', 'profile_sidebar_border_color': '000000', 'profile_sidebar_fill_color': '000000', 'profile_text_color': '000000', 'profile_use_background_image': False, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'can_media_tag': True, 'followed_by': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none'}, id=704772464769765376, id_str='704772464769765376', name='Harshika Jain', screen_name='harshikerfuffle', location='Pittsburgh, PA', description='User Experience Designer | NIDian | Tartan', url='https://t.co/ZZ9imZvwFE', entities={'url': {'urls': [{'url': 'https://t.co/ZZ9imZvwFE', 'expanded_url': 'http://cryptdecrypt.blogspot.in', 'display_url': 'cryptdecrypt.blogspot.in', 'indices': [0, 23]}]}, 'description': {'urls': []}}, protected=False, followers_count=99, friends_count=393, listed_count=2, created_at=datetime.datetime(2016, 3, 1, 20, 57, 4), favourites_count=687, utc_offset=None, time_zone=None, geo_enabled=False, verified=False, statuses_count=421, lang=None, contributors_enabled=False, is_translator=False, is_translation_enabled=False, profile_background_color='000000', profile_background_image_url='http://abs.twimg.com/images/themes/theme9/bg.gif', profile_background_image_url_https='https://abs.twimg.com/images/themes/theme9/bg.gif', profile_background_tile=False, profile_image_url='http://pbs.twimg.com/profile_images/1141340441939513346/zLPwA6rs_normal.png', profile_image_url_https='https://pbs.twimg.com/profile_images/1141340441939513346/zLPwA6rs_normal.png', profile_banner_url='https://pbs.twimg.com/profile_banners/704772464769765376/1457153670', profile_link_color='19CF86', profile_sidebar_border_color='000000', profile_sidebar_fill_color='000000', profile_text_color='000000', profile_use_background_image=False, has_extended_profile=False, default_profile=False, default_profile_image=False, can_media_tag=True, followed_by=False, following=False, follow_request_sent=False, notifications=False, translator_type='none'), geo=None, coordinates=None, place=None, contributors=None, is_quote_status=False, retweet_count=0, favorite_count=0, favorited=False, retweeted=False, lang='en')"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.update_status(\n",
    "  'this is a reply! @@CMUInnovation', status.author.screen_name,\n",
    "  status.id_str\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.9350, 0.0650]))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(\"Why poor people tend to be more generous than the rich\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.2322, 0.7678]))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(\"World bank says poor need more money\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.8743, 0.1257]))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(\"Police: Fake Money Making The Rounds In Pittsburgh Area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.7909, 0.2091]))"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(\"Police: Fake Money making The bloopers In Pittsburgh Area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.1094, 0.8906]))"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(\"Man throws 20ft up National Christmas Tree near White House\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 0, tensor(0), tensor([0.8012, 0.1988]))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(\"I Accidentally Uncovered a Nationwide Scam on 9Gag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.1536, 0.8464]))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(\"Parents Scale school Building to Help Students cheat on Exams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.2849, 0.7151]))"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(\"Man Buys Solid Gold Shirt to score with the Ladies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.1436, 0.8564]))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify.predict(\"Parents Scale office building to Help apple cheat off Exams\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
